{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Q5r9ijpS9qgEh9n3GOq4JJHxD8xm7hvO","timestamp":1609251197901}],"collapsed_sections":[],"authorship_tag":"ABX9TyPf+FpTNbQDDpEbqzSHZfGA"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RtRAfIVCTM0Z","executionInfo":{"status":"ok","timestamp":1647278415304,"user_tz":-240,"elapsed":35128,"user":{"displayName":"Глеб Русанов","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhzMtVVAgySzdWd5C-q-4elvs-5iABv4J1hbVv9=s64","userId":"00041069074378731884"}},"outputId":"fd4a156e-79f6-4709-b26f-180df254c965"},"source":["#ПОДКЛЮЧЕНИЕ ГУГЛ ДИСКА И ИМПОРТ НЕОБХОДИМЫХ БИБЛИОТЕК\n","# Подключение Гугл диска\n","from google.colab import drive\n","drive.mount('/content/drive/') #Путь до гугл диска (добавить My Drive в конец)\n","import matplotlib #Для работы с графиками\n","matplotlib.use('Agg') #Необходимо для работы matplotlib\n","from __future__ import absolute_import, division, print_function, unicode_literals\n","import tensorflow as tf\n","from tensorflow import keras #Для работы с нейросетью\n","from sklearn.model_selection import train_test_split #для работы с датасетами\n","from sklearn.metrics import classification_report \n","from keras.models import Sequential #модель нейросети\n","from keras.layers.core import Dense #описание полносвязного слоя\n","#from keras.optimizers import SGD #опримизатор\n","\n","from sklearn.preprocessing import StandardScaler\n","#from sklearn.externals import joblib\n","\n","from imutils import paths \n","import matplotlib.pyplot as plt\n","import numpy as np #для работы с массивами\n","import random #для перемешивания массивов\n","import pickle#для сохранения модели нейросети\n","import cv2 #для работы с изображениями \n","import os #для работы с файлами и путями\n","from keras.callbacks import EarlyStopping\n","from keras.callbacks import ModelCheckpoint"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","metadata":{"id":"jSyxMItCTVX3"},"source":["#ОТКРЫТИЕ И СТАНДАРТИЗАЦИЯ\n","\n","ImagePathss = list(paths.list_images(\"/content/drive/My Drive/archive.zip (Unzipped Files)/data/with_mask/\"))#откраваем папку с масками\n","#ImagePathss=ImagePathss[:4000] #первые [несколько] изображений для ускорения стандартизации\n","random.seed(42)\n","random.shuffle(ImagePathss)#Перемешивание для лучшего обучения нейросети\n","ImagePath=list(paths.list_images(\"/content/drive/My Drive/archive.zip (Unzipped Files)/data/without_mask/\"))#откраваем папку с фото без масок\n","#ImagePath=ImagePath[:4000]\n","ImagePaths=ImagePath+ImagePathss # Теперь в ImagePaths список путей к картинкам\n","random.shuffle(ImagePaths)\n","print(len(ImagePaths))\n","data,labels,i=[],[],0\n","for img in ImagePaths: #В переменную img сохраняется одн из путей к картинке \n","  image = cv2.imread(img)\n","  o=False\n","  #Если изображение не читается то метка и изображение не записываются в data и labels\n","  try:\n","    image = cv2.resize(image, (50, 50)).flatten() #Обрезаем изображение без сохранения пропорций\n","  except:\n","    o=True\n","    print(\"*\")\n","  if o != True:\n","    data.append(image)\n","    label = img.split(os.path.sep)[-2]#в переменную label сохраняется название папки, в которой лежит фото\n","    if label == 'With_mask':\n","      label = [1,0]\n","    else:\n","      label = [0,1]\n","    labels.append(label)\n","    i+=1\n","    print(i)#Для отобрашения работы\n","print(len(data)) # Количество всех успешно прочитанных изображений\n","data = np.array(data, dtype=\"float\")/255.0 #перевод в массив чисел numpy\n","labels = np.array(labels)#перевод в массив чисел numpy\n","\n","\n","with open(\"/content/drive/My Drive/data_mask.pickle\", 'wb') as f:\n","  pickle.dump(data, f)                                                                  #data_mask (Изображения в виде массива цафр) и labels_mask (Метки [1,0] или [1,0])    \n","print(\"Data seved\")                                                                        #Cохраняются в Гугл диск, не проводить долгую процедуру стандартизации ещё раз\n","with open(\"/content/drive/My Drive/labels_mask.pickle\", 'wb') as f:\n","  pickle.dump(labels, f)\n","print(\"Labels seved\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FSlHfNAIx-rg"},"source":["from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.linear_model import LinearRegression\n","\n","import random\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder \n","with open(\"/content/drive/My Drive/data_mask.pickle\", 'rb') as f:\n","  data = pickle.load(f)                                                                         #Открытие набора картинок и меток c Google диска                                                                        \n","with open(\"/content/drive/My Drive/labels_mask.pickle\", 'rb') as f:\n","  labels = pickle.load(f)\n","trainX, testX, trainY, testY = train_test_split(data, labels, test_size=0.15) #Деление датасета на тестовые и рабочие(для обучения) данные\n","#print('Dataset prepared')\n","\n","\n","np.array(trainX)\n","\n","\n","\n","\n","#test=trainY(columns=['1','2'])\n","#le = LabelEncoder)\n","#trainY['1'] = le.transform(test['1'])\n","\n","\n","#lr = LinearRegression()\n","#print(trainX)\n","#print(trainY.shape)\n","#lr.fit(trainX, trainY)\n","#predictions = lr.predict(testX)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1D7UecycEn9Y"},"source":["test=cv2.imread(\"/content/drive/My Drive/mask.jpg\")\n","test1=[]\n","test = cv2.resize(test, (50, 50)).flatten()\n","test1.append(test)\n","test1 = np.array(test1, dtype=\"float\")/255.0\n","predictions = lr.predict(test1)\n","print(predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kETujnBEUlb0"},"source":["#Проверка\n","test1=[]\n","scaler = StandardScaler()\n","X = scaler.fit_transform(trainX)\n","model.save(\"/content/drive/My Drive/model4.h5\")#Сохранение модели нейросети\n","test=cv2.imread(\"/content/drive/My Drive/mask.jpg\")\n","test = cv2.resize(test, (50, 50)).flatten()\n","test1.append(test)\n","test1 = np.array(test1, dtype=\"float\")/255.0\n","predictions = model.predict (test1)\n","print(predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L1GGwrAvTbJx"},"source":["#Создание модели нейронной сети и обучение\n","\n","\n","'''\n","model = Sequential()\n","model.add(Dense(2500, input_shape=(7500,), activation='sigmoid')) #Добавляем первый слой с количеством входов = \n","model.add(Dense(500, activation='sigmoid'))                                                               #количество цветов * высота в пикселях * ширина в пикселях\n","model.add(Dense(2, activation='softmax'))\n","'''\n","model = Sequential()\n","model.add(Dense(2500, input_shape=(7500,), activation='sigmoid')) #Добавляем первый слой с количеством входов = \n","model.add(Dense(3000, activation='sigmoid'))                                                               #количество цветов * высота в пикселях * ширина в пикселях\n","model.add(Dense(500, activation='sigmoid'))                                                               #количество цветов * высота в пикселях * ширина в пикселях\n","model.add(Dense(2, activation='softmax'))\n","\n","INIT_LR = 0.01\n","opt = SGD(lr=INIT_LR)\n","model.compile(loss='binary_crossentropy', optimizer = opt, metrics=['accuracy'])\n","print('Model compiled')\n","EPOCHS=60\n","Batch_size=64\n","checkpointer = ModelCheckpoint(filepath='/content/drive/My Drive/point.h5', verbose=1, save_best_only=True)\n","H=model.fit(trainX, trainY, validation_data=(testX,testY),\n","              epochs=EPOCHS, batch_size=Batch_size,\n","              callbacks=[checkpointer])#обучение  нейросети\n","print(\"Model trained\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zoKZhyF6NrFS"},"source":["#ПОСТРОЕНИЕ ГРАФИКА\n","N = np.arange(0, EPOCHS)\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n","plt.plot(N, H.history[\"val_loss\"], label=\"vall_loss\")\n","plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n","plt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\n","plt.title(\"Results\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss/Accuracy/\")\n","plt.legend()\n","plt.savefig(\"/content/drive/My Drive/Loss.png\")\n","model.save(\"model.h5\")\n","print(\"End\")"],"execution_count":null,"outputs":[]}]}